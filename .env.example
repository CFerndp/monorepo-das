# Ollama Configuration
# Specify which models to download automatically (comma-separated)
# Examples: llama3.2:3b, llama3.2:1b, mistral, codellama, phi3
OLLAMA_MODELS=llama3.2:3b

# You can specify multiple models separated by commas:
# OLLAMA_MODELS=llama3.2:3b,mistral:7b,codellama:7b

# Common models:
# - llama3.2:1b (smallest, fastest)
# - llama3.2:3b (balanced)
# - llama3.2:7b (more capable)
# - mistral:7b (good for general tasks)
# - codellama:7b (optimized for code)
# - phi3:mini (Microsoft's small model)

# Database Configuration (Backend)
USE_POSTGRES=true
POSTGRES_DB=das_db
POSTGRES_USER=das_user
POSTGRES_PASSWORD=das_password
POSTGRES_HOST=postgres
POSTGRES_PORT=5432

# Django Settings (Backend)
DJANGO_SECRET_KEY=change-this-in-production
DEBUG=True
ALLOWED_HOSTS=localhost,127.0.0.1,0.0.0.0

# Frontend Configuration
NODE_ENV=production
NEXT_PUBLIC_API_URL=http://localhost:8000
